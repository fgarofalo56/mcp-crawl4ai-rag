# The transport for the MCP server - either 'sse' or 'stdio' (defaults to sse if left empty)
TRANSPORT=

# Host to bind to if using sse as the transport (leave empty if using stdio)
# Set this to 0.0.0.0 if using Docker, otherwise set to localhost (if using uv)
HOST=

# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=

# Azure OpenAI Configuration
# Set these variables if using Azure OpenAI instead of OpenAI API
# Azure OpenAI endpoint URL (e.g., https://your-resource.openai.azure.com/)
AZURE_OPENAI_ENDPOINT=

# Azure OpenAI API key
AZURE_OPENAI_API_KEY=

# Azure OpenAI API version (e.g., 2024-10-01-preview)
AZURE_OPENAI_API_VERSION=2024-10-01-preview

# Azure OpenAI deployment name for chat completions
DEPLOYMENT=

# Azure OpenAI model name (e.g., gpt-4, gpt-35-turbo)
OPENAI_MODEL=

# Azure OpenAI deployment name for embeddings (e.g., text-embedding-3-small)
EMBEDDING_DEPLOYMENT=text-embedding-3-small

# The LLM you want to use for summaries and contextual embeddings
# For Azure, this should match your deployment name
MODEL_CHOICE=

# Legacy OpenAI API Key (kept for backward compatibility)
# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# This is for the embedding model - text-embed-small-3 will be used
OPENAI_API_KEY=

# RAG strategies - set these to "true" or "false" (default to "false")
# USE_CONTEXTUAL_EMBEDDINGS: Enhances embeddings with contextual information for better retrieval
USE_CONTEXTUAL_EMBEDDINGS=false

# USE_HYBRID_SEARCH: Combines vector similarity search with keyword search for better results
USE_HYBRID_SEARCH=false

# USE_AGENTIC_RAG: Enables code example extraction, storage, and specialized code search functionality
USE_AGENTIC_RAG=false

# USE_RERANKING: Applies cross-encoder reranking to improve search result relevance
USE_RERANKING=false

# USE_KNOWLEDGE_GRAPH: Enables AI hallucination detection and repository parsing tools using Neo4j
# If you set this to true, you must also set the Neo4j environment variables below.
USE_KNOWLEDGE_GRAPH=false

# USE_GRAPHRAG: Enables GraphRAG - document knowledge graph with entity extraction from web content
# This creates a knowledge graph from crawled web pages, extracting entities and relationships.
# Enables graph-augmented RAG for richer context and multi-hop reasoning.
# Requires Neo4j (same as USE_KNOWLEDGE_GRAPH) AND OpenAI API for entity extraction.
# If you set this to true, you must set Neo4j and OpenAI environment variables.
USE_GRAPHRAG=false

# For the Supabase version (sample_supabase_agent.py), set your Supabase URL and Service Key.
# Get your SUPABASE_URL from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=your_supabase_url_here
SUPABASE_KEY=your_supabase_key_here

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password_here

# Optional: Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Optional: Crawl4AI Settings
MAX_CONCURRENT_CRAWLS=10
DEFAULT_CHUNK_SIZE=5000

# Get your SUPABASE_SERVICE_KEY from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
# On this page it is called the service_role secret.
SUPABASE_SERVICE_KEY=

# Neo4j Configuration for Knowledge Graph Tools
# These are required for the AI hallucination detection and repository parsing tools
# Leave empty to disable knowledge graph functionality

# Neo4j connection URI
# ============================================================================
# IMPORTANT: The URI changes based on how you're running the MCP server!
# ============================================================================
#
# OPTION 1: Running MCP server LOCALLY with uv (NOT in Docker)
#   Use localhost to connect to Neo4j running on your machine
NEO4J_URI=bolt://localhost:7687
#
# OPTION 2: Running MCP server in DOCKER
#   Choose one of these based on where your Neo4j is running:
#
#   2a. Neo4j on HOST machine (most common for development):
#       Use host.docker.internal to connect from Docker to your host
#   NEO4J_URI=bolt://host.docker.internal:7687
#
#   2b. Neo4j in DOCKER COMPOSE (see docker-compose.yml):
#       Use the service name from docker-compose.yml
#   NEO4J_URI=bolt://neo4j:7687
#
#   2c. Neo4j in CLOUD (AuraDB):
#       Use neo4j+s:// protocol with your cloud instance URL
#   NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
#
# ============================================================================

# Neo4j username (usually 'neo4j' for default installations)
NEO4J_USER=neo4j

# Neo4j password for your database instance
NEO4J_PASSWORD=