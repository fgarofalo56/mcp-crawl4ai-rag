services:
  # MCP Crawl4AI Server
  mcp-server:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        PORT: ${PORT:-8051}

    container_name: mcp-crawl4ai-server
    restart: unless-stopped

    ports:
      - "${PORT:-8051}:${PORT:-8051}"

    # Load environment variables from .env.docker file
    env_file:
      - .env.docker

    environment:
      # Transport configuration
      - TRANSPORT=${TRANSPORT:-sse}
      - HOST=0.0.0.0
      - PORT=${PORT:-8051}

      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MODEL_CHOICE=${MODEL_CHOICE:-gpt-4.1-nano}

      # Azure OpenAI (if using Azure instead)
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY:-}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2024-10-01-preview}
      - DEPLOYMENT=${DEPLOYMENT:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4}
      - EMBEDDING_DEPLOYMENT=${EMBEDDING_DEPLOYMENT:-text-embedding-3-small}

      # Supabase Configuration
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}

      # RAG Strategies
      - USE_CONTEXTUAL_EMBEDDINGS=${USE_CONTEXTUAL_EMBEDDINGS:-false}
      - USE_HYBRID_SEARCH=${USE_HYBRID_SEARCH:-false}
      - USE_AGENTIC_RAG=${USE_AGENTIC_RAG:-false}
      - USE_RERANKING=${USE_RERANKING:-false}
      - USE_KNOWLEDGE_GRAPH=${USE_KNOWLEDGE_GRAPH:-false}
      - USE_GRAPHRAG=${USE_GRAPHRAG:-false}

      # Neo4j Configuration (connects to external Neo4j deployment)
      - NEO4J_URI=${NEO4J_URI:-bolt://host.docker.internal:7687}
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-}

      # Crawl4AI Settings
      - MAX_CONCURRENT_CRAWLS=${MAX_CONCURRENT_CRAWLS:-10}
      - DEFAULT_CHUNK_SIZE=${DEFAULT_CHUNK_SIZE:-5000}

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:${PORT:-8051}/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
